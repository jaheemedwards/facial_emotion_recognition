# -*- coding: utf-8 -*-
"""facial_emotion_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pZt1Wncs5ZmPjGqr9JtUTiTKu9GTni-4
"""

!pip install kagglehub --upgrade

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

from tensorflow.keras import layers, models, optimizers, losses, metrics
from tensorflow.keras.callbacks import EarlyStopping
import os
import kagglehub

print("TensorFlow version:", tf.__version__)
print("GPU available:", tf.config.list_physical_devices('GPU'))

# Download the dataset
path = kagglehub.dataset_download("fahadullaha/facial-emotion-recognition-dataset")

print("Path to dataset files:", path)

# List files in the dataset folder
os.listdir(path)

!apt install tree -y
!tree $path -L 2

data_dir = "/kaggle/input/facial-emotion-recognition-dataset/processed_data"

dataset = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    image_size=(96, 96),
    batch_size=32,
    color_mode="grayscale"
)

from PIL import Image

# loop over a few classes and images
for emotion in os.listdir(data_dir):
    emotion_path = os.path.join(data_dir, emotion)
    if os.path.isdir(emotion_path):
        for i, img_file in enumerate(os.listdir(emotion_path)):
            img_path = os.path.join(emotion_path, img_file)
            img = Image.open(img_path)
            print(f"{img_file} - size: {img.size} - mode: {img.mode}")
            if i >= 2:  # check first 3 images per class
                break
print("Classes: ", dataset.class_names)

train_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(96, 96),
    batch_size=32,
    color_mode="rgb",
    label_mode="categorical"
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(96, 96),
    batch_size=32,
    color_mode="rgb",
    label_mode="categorical"
)

class_names = train_ds.class_names
print("Classes:", class_names)

import matplotlib.pyplot as plt
import tensorflow as tf

plt.figure(figsize=(10,10))
for images, labels in train_ds.take(1):
    for i in range(9):
        plt.subplot(3,3,i+1)
        plt.imshow(images[i].numpy().astype("uint8"))  # RGB image
        plt.title(class_names[tf.argmax(labels[i])])
        plt.axis('off')
plt.show()

AUTOTUNE = tf.data.AUTOTUNE
normalization_layer = tf.keras.layers.Rescaling(1./255)

data_augmentation = tf.keras.Sequential([
  layers.RandomFlip("horizontal"),
  layers.RandomRotation(0.1),
  layers.RandomZoom(0.1)
])

train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

import matplotlib.pyplot as plt
import tensorflow as tf

plt.figure(figsize=(10,10))
for images, labels in train_ds.take(1):
    for i in range(9):
        plt.subplot(3,3,i+1)
        plt.imshow(images[i].numpy().astype("uint8"))  # RGB image
        plt.title(class_names[tf.argmax(labels[i])])
        plt.axis('off')
plt.show()

model = models.Sequential([
    layers.Input(shape=(96, 96, 3)),   # explicitly define input

    layers.Conv2D(16, (3,3), 1, activation='relu'),
    # layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(32, (3,3), 1,activation='relu'),
    # layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), 1,activation='relu'),
    # layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(32, (3,3), 1,activation='relu'),
    # layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(16, (3,3), 1,activation='relu'),
    # layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Flatten(),

    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(7, activation='softmax')  # 7 classes for emotions
])

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20
    # callbacks=early_stop
)

import matplotlib.pyplot as plt

# Extract metrics
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc)+1)

# Plot Accuracy
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plot Loss
plt.subplot(1,2,2)
plt.plot(epochs, loss, 'b', label='Training Loss')
plt.plot(epochs, val_loss, 'r', label='Validation Loss')
plt.title('Training vs Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy

pre = Precision()
re = Recall()
acc = CategoricalAccuracy()

# Loop through test dataset
for batch in val_ds.as_numpy_iterator():  # or val_ds if testing on validation set
    X, y = batch
    yhat = model.predict(X, verbose=0)
    pre.update_state(y, yhat)
    re.update_state(y, yhat)
    acc.update_state(y, yhat)

# Print results
print(f'Precision: {pre.result().numpy():.4f}')
print(f'Recall: {re.result().numpy():.4f}')
print(f'Accuracy: {acc.result().numpy():.4f}')

import cv2
import os
from google.colab.patches import cv2_imshow

image_files = [
    "angrytest.jpg", "disgusttest.jpg", "fearfultest.jpg",
    "happytest.jpg", "sadtest.jpg", "neutraltest.jpg", "surprisetest.jpg"
]

for img_name in image_files:
    img = cv2.imread(img_name)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.show()

    resize = tf.image.resize(img, (96,96))
    plt.imshow(resize.numpy().astype(int))
    plt.show()

for img_name in image_files:
    img = cv2.imread(img_name)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
for img_name in image_files:
    img = cv2.imread(img_name)

    # Check if image exists
    if img is None:
        print(f"‚ùå Could not load {img_name}")
        continue

    # Convert BGR to RGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Resize for model
    resize = tf.image.resize(img_rgb, (96, 96))

    # Prepare input for model
    img_input = np.expand_dims(resize / 255.0, axis=0)

    # Predict
    yhat = model.predict(img_input, verbose=0)
    predicted_class = class_names[np.argmax(yhat)]

    # Show image with filename + prediction
    plt.imshow(resize.numpy().astype(int))
    plt.title(f"Image: {img_name} | Predicted: {predicted_class}")
    plt.axis('off')
    plt.show()

    print(f"Image: {img_name}")
    print("Prediction probabilities:", yhat)
    print("Predicted class:", predicted_class)
    print("---------")

    resize = tf.image.resize(img, (96,96))
    plt.imshow(resize.numpy().astype(int))
    np.expand_dims(resize, 0)
    yhat = model.predict(np.expand_dims(resize/255, 0))
    print(yhat)
    print(class_names[np.argmax(yhat)])

from tensorflow.keras.models import load_model

model.save("facial_emotion_model.keras")
new_model = load_model("facial_emotion_model.keras")